---
title: "p8105_hw5_fj2269"
author: "Fangming Jin"
date: "2019/11/1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
```

### Question 1

**1. import the data**

```{r Q1S1SS1}
set.seed(10)
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
iris_with_missing
```

**2. write the function and apply it to iris_with_missing

```{r Q1S1SS2}
replace_function = function(x){
  
  if (is.numeric(x)) {
    y = mean(x, na.rm = TRUE)
    x = replace_na(x, y)
  } else if (is.character(x)) {
    x = replace_na(x, "virginica")
  }
  x
}
iris_with_missing = map_df(iris_with_missing, replace_function)
iris_with_missing
```

### Question 2

**1. tidy the data**

```{r Q2S1, warning=FALSE}
longitudinal = tibble(name = list.files('./Q2/hw5_data/data')) %>%
  mutate(result = map(.x = str_c("./Q2/hw5_data/data/",name), ~read.csv(file = .x))) %>%
  janitor::clean_names() %>%
  separate(name, c("arm", "ID"), sep = "([\\_\\.])") %>%
  mutate(arm = recode(arm, "con"="control","exp"="experimental")) %>%
  mutate(result = map(result, as.numeric())) %>%
  drop_na()
longitudinal
longitudinal %>% unnest %>% unnest
```

**2. make spaghetti plot**

```{r Q2S2}
plot_spag = longitudinal %>% 
  unnest %>% unnest %>%
  pivot_longer(
    week_1:week_8, 
    names_to = "week", 
    values_to ="data", 
    names_prefix = "week_") %>%
  ggplot(aes(x = week, y = data, group = ID, color = ID)) + 
    geom_line(size=1) + 
    facet_grid(~arm) +
    labs(title = "Observations on each subject in two groups over time", y = "longitudinal data") + 
    theme(plot.title = element_text(hjust = 0.5), legend.position = "right") +
    viridis::scale_color_viridis(discrete = TRUE) 
plot_spag
```

The longitudinal data in control group does not change over time, and longitudinal data in exprimental group increases significantly as time passes. In first two weeks the longitudinal data in experimental group is close to that in control group. But as time pass, the longitudinal data in experimental group is significanty higher than that in control group. 

### Question 3

**1.simulation**

```{r Q3S1}
set.seed(12)
sim_regression = function(n = 30, beta0 = 2, beta1) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, sqrt(50))
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta1_hat = coef(ls_fit)[2],
    beta1_p_value = pull(broom::tidy(ls_fit),p.value)[[2]]
  )
}
output = 
  tibble(beta1_true = c(0:6)) %>% 
  mutate(
    output_lists = map(.x = beta1_true, ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
```

**2.The relationship between effect size and power**

```{r Q3S2}
output %>%
  filter(beta1_p_value < 0.05) %>%
  group_by(beta1_true) %>%
  summarize(
    prop_reject = n()/10000
  ) %>%
  ggplot(aes(x = beta1_true, prop_reject, color = prop_reject)) +
    theme_bw() + 
    geom_point(size = 2, alpha = 0.5) +
    scale_color_gradientn(colors=c("darkred", "orange", "yellow")) +
    labs(title = "proportion of times that null was rejected by true beta1 value", x="true beta1 value", y="proportion of rejection") +
    theme(plot.title = element_text(hjust = 0.5),legend.position = "none") +
    scale_x_continuous(
    breaks = c(0,1,2,3,4,5,6), 
    labels = c(0,1,2,3,4,5,6)) 
  
```

We already know β1 in H0 and H1:in H0, β1=0， in H1, β1 is equal to true beta that we have already known(β1 = {0,1,2,3,4,5,6}).

Effect size is calculated by taking the difference between β in H0 and H1 and dividing it by sd. In this test, sd is equal to error term's sd, σ. 

Based on graph above, as true beta increases, effect size increases, proportion of rejection increases. This means the proportion of rejecting false null hypothesis increases as effect size increases, power increases as effect size increases. 

**3.**

```{r Q3S3SS1}
mean_sum = output %>%
  group_by(beta1_true) %>%
  summarize(
    mean_beta1 = mean(beta1_hat)
  ) %>%
  mutate(group = rep("complete sample"))
mean_reject = output %>%
  filter(beta1_p_value < 0.05) %>%
  group_by(beta1_true) %>%
  summarize(
    mean_beta1 = mean(beta1_hat)
  ) %>%
  mutate(group = rep("sample that null is rejected"))
mean_beta1 = bind_rows(mean_reject, mean_sum) 
ggplot(mean_beta1, aes(x = beta1_true, y = mean_beta1, group = group, color = group)) +
  theme_bw() + 
  geom_point(size = 2, alpha = 0.5) +
  geom_smooth(se = FALSE) +
  labs(title = "average estimate of beta1 by true beta1 value", x="true beta1 value", y="average estimate of beta1") +
  viridis::scale_color_viridis(
    name = "sample scale", 
    discrete = TRUE
  ) +
  theme(plot.title = element_text(hjust = 0.5),legend.position = "bottom") +
  scale_x_continuous(
    breaks = c(0,1,2,3,4,5,6), 
    labels = c(0,1,2,3,4,5,6)) + 
  scale_y_continuous(
    breaks = c(0,1,2,3,4,5,6), 
    labels = c(0,1,2,3,4,5,6))
```

According to graph above, the sample average of estimated β1 across tests for complete sample is close to the true value of β1 no matter how much true β1 is. But the sample average of estimated β1 across tests for which the null is rejected does not equal to the true value of β1 when β1 is 1, 2 and 3. The value of estimated β1 for sample that null is rejected is close to value of true β1 when β1 is small(β1 = 0) or β1 is big(β1 = 4, 5 and 6)